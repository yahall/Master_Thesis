{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"background-color:#5d3a8e; color:white; padding:0px 10px; border-radius:5px;\"><h1 style='margin:10px 5px'> \n",
    "Master Thesis Yannik Haller - Sentiment Analysis TEXTBLOB\n",
    "</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"background-color:#5d3a8e; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'> \n",
    "1. Load required packages and the data\n",
    "</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hallk\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\pylab\\config.py:70: DeprecationWarning: InlineBackend._figure_formats_changed is deprecated in traitlets 4.1: use @observe and @unobserve instead.\n",
      "  def _figure_formats_changed(self, name, old, new):\n"
     ]
    }
   ],
   "source": [
    "# Import required baseline packages\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "# Change pandas' setting to print out long strings\n",
    "pd.options.display.max_colwidth = 200\n",
    "\n",
    "# Plotting tools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# TextBlob (for Sentiment Analysis)\n",
    "from textblob import Blobber\n",
    "from textblob_de import PatternTagger, PatternAnalyzer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category = DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category = FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the appropriate working directory\n",
    "os.chdir('D:\\\\Dropbox\\\\MA_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to read in the fully preprocessed data (note: we are using the preprocessed data in which negations are preserved --> PPII)\n",
    "def read_preprocessed(language, tokenize = True):\n",
    "    # Raise an error if an inadmissible language is chosen\n",
    "    allowed_languages = ['de', 'en', 'fr', 'it']\n",
    "    if language not in allowed_languages:\n",
    "        raise ValueError(\"Invalid language. Expected one of: %s\" % allowed_languages)\n",
    "    \n",
    "    # Set the appropriate working directory\n",
    "    os.chdir('D:\\\\Dropbox\\\\MA_data')\n",
    "\n",
    "    # Define the name of the file to load\n",
    "    filename = \"Preprocessed/Sentiment_Analysis/\"+language+\"_preprocessed_senti.csv\"\n",
    "\n",
    "    # Read in the dataframe containing the text data\n",
    "    tx_pp = pd.read_csv(filename, index_col = 0, dtype = {'tx': object})\n",
    "\n",
    "    # Get the articles' index together with an enumeration to identify their position in the list of precleaned articles\n",
    "    idx = tx_pp.index\n",
    "    idx = pd.DataFrame(idx, columns = [language+'_idx'])\n",
    "\n",
    "    # Reduce the dataframe to a list containing the text data\n",
    "    tx_pp = tx_pp.tx.to_list()\n",
    "\n",
    "    # Tokenize the data again if tokenize = True (RAM-saving)\n",
    "    if tokenize:\n",
    "        tx_pp = retokenize(tx_pp)\n",
    "\n",
    "    # Return the preprocessed data\n",
    "    return tx_pp, idx\n",
    "\n",
    "# Define a function to retokenize the preprocessed text data (RAM-saving)\n",
    "def retokenize(article_list):\n",
    "    for i in range(len(article_list)):\n",
    "        temp_tx = str(article_list[i]).split()\n",
    "        article_list[i] = temp_tx\n",
    "    return article_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15474568"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the preprocessed data (not tokenized)\n",
    "de_tx, de_idx = read_preprocessed('de', tokenize = False)\n",
    "\n",
    "# Take a look at the size of the precleaned data\n",
    "sys.getsizeof(de_tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rückkehrer stefan meier überragen flames herisau bangen allerdings schluss lukas pfiffnerin vergangen saison tun uhc herisau darin immer wieder rückstand aufholen partie kehren noch jung liga meisterschaft leben team mindestens heimspiel neu trend deutlich führung noch zittern samstag lagen überzeugend ausserrhoder vorne reagieren ausgleich flames tor dreier minute besassen stefan meier saison wasa verteidigen sommer nla stammverein zurückkehren herausragenden stürmer minute sirene hiess fünft mal meier stock spiel sicherheit ball gehen allerdings auch führung verlieren komplette zusammenbruch drohen flames können aber gewicht nicht total verschieben eindrücklich effort niklas hess tragen gastgeber sieg trainer sagen grosses kino schon woche zuvor meier einzig herisauer niederlage pfannenstiel egg treffer erzielen liegen tor assists nun platz skorer gruppe meier bewegen messen cm grösse kg gewicht erstaunlich geschmeidig können ball behaupten weisen wuchtig schuss so laufen aktuell vorne natürlich schön meinen jährig harmonieren linienpartnern joel conzett silas stucki vorzüglich kreativ trainer nico raschle sprechen grossem kino meier auftritt samstag allgemein einstellung betreffen nicht liga kommen karriere einfach wenig ausplämperlen lassen bestätigen meier indirekt ganz gut neue position zuteilen bekommen da können nochmals richtig reinhängen warum spielen meier herisau vorne erhoffen heute gelingen sagen raschle resultatmässigen notstand muss auch einmal entscheid rückgängig machen flames innert sekunde tor schießen trainer nehmen beordern meier letzt minute verteidigung problem kurzfristig umstellung nicht meinen abwehr machen routine positionsspiel zudem jahrelang torhüter dominic jud rücken verteidigen kennen anweisung genau sonntagabend cupeinsatzfür herisau bringen samstag viert spiel dritt erfolg belegen zweit platz punkt partie bassersdorf nürensdorf saison nicht mehr effektiv punkt erstellung tabelle berücksichtigen quotient bisher geben gruppe corona allerdings noch kein spielabsagen sonntagabend treten ausserrhoder ligisten grab werdenberg cupspiel herisau flames sportzentrum zuschauer sr cereda locatelli tor meier penalty meier stucki mattsson bernet liechti jenny conzett meier conzett meier germann brand swoboda meier stucki jud mattsson ausschluss schilling dürr jud mattsson rautio hess herisau jud brunner schwarz rüegg schmid stern stucki schweizer hess schilling sandmeier stucki conzett meier germann mittelholzer wetter brand strafe je mal minute konzentration schluss herisaus torhüter dominic jud sehen schuss zukommen bild lukas pfiffner'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the preprocessed data\n",
    "de_tx[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1934310</th>\n",
       "      <td>2441180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1934311</th>\n",
       "      <td>2441181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1934312</th>\n",
       "      <td>2441182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          de_idx\n",
       "1934310  2441180\n",
       "1934311  2441181\n",
       "1934312  2441182"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the dataframe containing the according index\n",
    "de_idx.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1934310, 1934311]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the location of the article in the preprocessed data using the according article id\n",
    "article_ids = [2441180, 2441181]\n",
    "location = de_idx[de_idx.de_idx.isin(article_ids)].index.tolist() #1934310\n",
    "\n",
    "# Access the preprocessed text from the articles with the article ids in [2441180, 2441181]\n",
    "#list(de_tx[i] for i in location)\n",
    "\n",
    "# Look at the according location of the articles with the article ids in [2441180, 2441181]\n",
    "location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"background-color:#5d3a8e; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'> \n",
    "2. Sentiment Assessment of the Articles\n",
    "</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that evaluates the polarity of the articles and stores the result to a correctly indexed csv file\n",
    "def eval_blob_polarity(tx, idx, outputfile_name = 'de_blob_polarity', batchsize = 100000, first_pos = 0):\n",
    "    # Notes: \n",
    "    ## tx has to be a list containing the precleaned and NOT tokenized articles\n",
    "    ## idx has to be a list containing the correctly ordered index\n",
    "\n",
    "    # Initialize a Blobber class, which uses the language specific PatternAnalyzer we imported above to assess text polarity (sentiment from -1 to 1) and subjectivity\n",
    "    tb = Blobber(pos_tagger = PatternTagger(), analyzer = PatternAnalyzer())\n",
    "\n",
    "    # Set up a loop to go through all articles and evaluate their polarity with TextBlob\n",
    "    i = first_pos\n",
    "    i_last_batch = first_pos\n",
    "    n_articles = len(tx)\n",
    "    pol = []\n",
    "    t = time.time()\n",
    "    for article in tx:\n",
    "        i = i + 1\n",
    "        pol.append(tb(article).sentiment[0])\n",
    "        if i % batchsize == 0 and i != (n_articles-first_pos):\n",
    "            print(\"Processing time to evaluate polarity scores of the articles at positions\", i_last_batch, \"to\", i-1, \":\", str(round((time.time() - t)/60,2)), \"minutes\")\n",
    "            i_last_batch = i\n",
    "            t = time.time()\n",
    "        if i == (n_articles-first_pos):\n",
    "            print(\"Processing time to evaluate polarity scores of the articles at positions\", i_last_batch, \"to\", i-1, \":\", str(round((time.time() - t)/60,2)), \"minutes\")\n",
    "            print(\"DONE! ;)\")\n",
    "\n",
    "    # Create a correctly indexed dataframe\n",
    "    Blob_tx_polarity = pd.DataFrame(pol, index = idx, columns = ['Blob_polarity'])\n",
    "    # Save the results to a csv file\n",
    "    Blob_tx_polarity.to_csv(\"Sentiment/TextBlob/\"+outputfile_name+\".csv\", index = True)\n",
    "    # Return the results\n",
    "    return Blob_tx_polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing time to evaluate polarity scores of the articles at positions 0 to 99999: 72.63 minutes\n",
      "Processing time to evaluate polarity scores of the articles at positions 100000 to 199999: 71.35 minutes\n",
      "Processing time to evaluate polarity scores of the articles at positions 200000 to 299999: 73.22 minutes\n",
      "Processing time to evaluate polarity scores of the articles at positions 300000 to 399999: 75.01 minutes\n",
      "Processing time to evaluate polarity scores of the articles at positions 400000 to 499999: 67.63 minutes\n",
      "Processing time to evaluate polarity scores of the articles at positions 500000 to 599999: 84.44 minutes\n",
      "Processing time to evaluate polarity scores of the articles at positions 600000 to 699999: 97.67 minutes\n",
      "Processing time to evaluate polarity scores of the articles at positions 700000 to 799999: 111.3 minutes\n",
      "Processing time to evaluate polarity scores of the articles at positions 800000 to 899999: 97.98 minutes\n",
      "Processing time to evaluate polarity scores of the articles at positions 900000 to 999999: 74.02 minutes\n",
      "DONE! ;)\n"
     ]
    }
   ],
   "source": [
    "# Apply the previously defined function on the first half of the German articles\n",
    "Blob_tx_polarity_1 = eval_blob_polarity(de_tx[:1000000], de_idx.de_idx.values.tolist()[:1000000], 'de_blob_polarity_batch1', 100000, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing time to evaluate polarity scores of the articles at positions 1000000 to 1099999 : 73.73 minutes\n",
      "Processing time to evaluate polarity scores of the articles at positions 1100000 to 1199999 : 77.15 minutes\n",
      "Processing time to evaluate polarity scores of the articles at positions 1200000 to 1299999 : 71.26 minutes\n",
      "Processing time to evaluate polarity scores of the articles at positions 1300000 to 1399999 : 75.04 minutes\n",
      "Processing time to evaluate polarity scores of the articles at positions 1400000 to 1499999 : 68.16 minutes\n",
      "Processing time to evaluate polarity scores of the articles at positions 1500000 to 1599999 : 64.96 minutes\n",
      "Processing time to evaluate polarity scores of the articles at positions 1600000 to 1699999 : 60.07 minutes\n",
      "Processing time to evaluate polarity scores of the articles at positions 1700000 to 1799999 : 85.88 minutes\n",
      "Processing time to evaluate polarity scores of the articles at positions 1800000 to 1899999 : 84.49 minutes\n",
      "Processing time to evaluate polarity scores of the articles at positions 1900000 to 1934312 : 28.37 minutes\n",
      "DONE! ;)\n"
     ]
    }
   ],
   "source": [
    "# Apply the previously defined function on the second half of the German articles\n",
    "Blob_tx_polarity_2 = eval_blob_polarity(de_tx[1000000:], de_idx.de_idx.values.tolist()[1000000:], 'de_blob_polarity_batch2', 100000, 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the results back in, concatenate them to one dataframe and save it as a csv file\n",
    "filenames = [\"Sentiment/TextBlob/de_blob_polarity_batch1.csv\", \"Sentiment/TextBlob/de_blob_polarity_batch2.csv\"]\n",
    "Blob_tx_polarity = pd.concat([pd.read_csv(f, index_col = 0, dtype = {'Blob_polarity': float}) for f in filenames])\n",
    "Blob_tx_polarity.to_csv(\"Sentiment/TextBlob/de_blob_polarity.csv\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blob_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16553</th>\n",
       "      <td>0.310417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16554</th>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16555</th>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16556</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16557</th>\n",
       "      <td>0.488889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441178</th>\n",
       "      <td>-0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441179</th>\n",
       "      <td>0.121429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441180</th>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441181</th>\n",
       "      <td>-0.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441182</th>\n",
       "      <td>0.558929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1934313 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Blob_polarity\n",
       "16553         0.310417\n",
       "16554         0.420000\n",
       "16555         0.850000\n",
       "16556         1.000000\n",
       "16557         0.488889\n",
       "...                ...\n",
       "2441178      -0.100000\n",
       "2441179       0.121429\n",
       "2441180       0.350000\n",
       "2441181      -0.433333\n",
       "2441182       0.558929\n",
       "\n",
       "[1934313 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the results\n",
    "Blob_tx_polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the concatenated results back in\n",
    "Blob_tx_polarity = pd.read_csv(\"Sentiment/TextBlob/de_blob_polarity.csv\", index_col = 0, dtype = {'Blob_polarity': float})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blob_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16553</th>\n",
       "      <td>0.310417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16554</th>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16555</th>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16556</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16557</th>\n",
       "      <td>0.488889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441178</th>\n",
       "      <td>-0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441179</th>\n",
       "      <td>0.121429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441180</th>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441181</th>\n",
       "      <td>-0.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441182</th>\n",
       "      <td>0.558929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1934313 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Blob_polarity\n",
       "16553         0.310417\n",
       "16554         0.420000\n",
       "16555         0.850000\n",
       "16556         1.000000\n",
       "16557         0.488889\n",
       "...                ...\n",
       "2441178      -0.100000\n",
       "2441179       0.121429\n",
       "2441180       0.350000\n",
       "2441181      -0.433333\n",
       "2441182       0.558929\n",
       "\n",
       "[1934313 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the read in results\n",
    "Blob_tx_polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The share of articles with a positive sentiment is 69.0 %\n",
      "The share of articles with a negative sentiment is 27.0 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blob_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1934313.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Blob_polarity\n",
       "count    1934313.000\n",
       "mean           0.177\n",
       "std            0.401\n",
       "min           -1.000\n",
       "25%           -0.028\n",
       "50%            0.198\n",
       "75%            0.434\n",
       "max            1.000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at some summary statistics\n",
    "share_pos = np.round(np.sum(Blob_tx_polarity['Blob_polarity'] > 0) / len(Blob_tx_polarity),2)\n",
    "share_neg = np.round(np.sum(Blob_tx_polarity['Blob_polarity'] < 0) / len(Blob_tx_polarity),2)\n",
    "print('The share of articles with a positive sentiment is', 100*share_pos,'%')\n",
    "print('The share of articles with a negative sentiment is', 100*share_neg,'%')\n",
    "np.round(Blob_tx_polarity.describe(), 3)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "89a54e7346d33656f2940aba0e47a561becf96fe36c69c035d9bc66d085d8900"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('Master_Thesis_env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
