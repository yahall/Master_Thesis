{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('Master_Thesis_env': conda)"
  },
  "interpreter": {
   "hash": "89a54e7346d33656f2940aba0e47a561becf96fe36c69c035d9bc66d085d8900"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "<div class=\"alert alert-info\" style=\"background-color:#5d3a8e; color:white; padding:0px 10px; border-radius:5px;\"><h1 style='margin:10px 5px'> \n",
    "Master Thesis Yannik Haller - Data Aggregation\n",
    "</h1>\n",
    "</div>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<div class=\"alert alert-info\" style=\"background-color:#5d3a8e; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'> \n",
    "1. Read in and aggregate/merge all csv-files \n",
    "</h2>\n",
    "</div>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<div class=\"alert alert-info\" style=\"background-color:#5d3a8e; color:white; padding:0px 10px; border-radius:5px;\"><h3 style='margin:10px 5px'> \n",
    "1.1 Pre-Aggregation \n",
    "</h3>\n",
    "</div>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Change pandas' setting to print out long strings\n",
    "pd.options.display.max_colwidth = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the appropriate working directory\n",
    "os.chdir('D:\\\\Dropbox\\\\MA_data')\n",
    "\n",
    "# Get a list containing all names of the files we want to load and aggregate\n",
    "extension = 'csv'\n",
    "filenames_older      = [i for i in glob.glob('Older/articles*'+'.{}'.format(extension))]\n",
    "filenames_oct_to_jan = [i for i in glob.glob('Oct-Jan/'+'*_Oct_2020_Jan_2021.{}'.format(extension))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "105\n93\n"
     ]
    }
   ],
   "source": [
    "# Check how many filenames are contained in the created lists\n",
    "print(len(filenames_older))\n",
    "print(len(filenames_oct_to_jan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    so so_txt pubDateTime  la  news_section  \\\n",
       "0  AGE  Agefi  2020-10-01  fr        la der   \n",
       "1  AGE  Agefi  2020-10-01  fr   entreprises   \n",
       "2  AGE  Agefi  2020-10-01  fr       marchés   \n",
       "\n",
       "                                                          title subtitle  \\\n",
       "0                     Les trois indices\\nclôturent dans le vert      NaN   \n",
       "1  Sika: le fabricant prévoit une embellie au deuxième semestre      NaN   \n",
       "2                     SMI dans le rouge, sous les 10.200 points      NaN   \n",
       "\n",
       "                                                                                                                                                                                                        tx  \\\n",
       "0  La Bourse de New York a terminé en hausse mercredi, sur les espoirs d'un prochain accord sur un nouveau plan d'aide économique américain qui a mené le Dow Jones brièvement au-dessus de 2% en séanc...   \n",
       "1  Le fabricant de spécialités chimiques Sika s'attend à une embellie au deuxième semestre malgré la crise pandémique qui continue de créer l'incertitude sur les marchés. Paul Schuler, directeur géné...   \n",
       "2  Le SMI a perdu 0,41% à 10.187,090 points, plus bas à 10.169,78 et plus haut à 10.266,97. Le SLI a cédé 0,08% à 1553,69 points et le SPI 0,27% à 12.724,65 points.Après avoir fait une pointe durant ...   \n",
       "\n",
       "                               author  \n",
       "0  McConnell, Mitch...Mnuchin, Steven  \n",
       "1                                 NaN  \n",
       "2                                 NaN  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>so</th>\n      <th>so_txt</th>\n      <th>pubDateTime</th>\n      <th>la</th>\n      <th>news_section</th>\n      <th>title</th>\n      <th>subtitle</th>\n      <th>tx</th>\n      <th>author</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AGE</td>\n      <td>Agefi</td>\n      <td>2020-10-01</td>\n      <td>fr</td>\n      <td>la der</td>\n      <td>Les trois indices\\nclôturent dans le vert</td>\n      <td>NaN</td>\n      <td>La Bourse de New York a terminé en hausse mercredi, sur les espoirs d'un prochain accord sur un nouveau plan d'aide économique américain qui a mené le Dow Jones brièvement au-dessus de 2% en séanc...</td>\n      <td>McConnell, Mitch...Mnuchin, Steven</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AGE</td>\n      <td>Agefi</td>\n      <td>2020-10-01</td>\n      <td>fr</td>\n      <td>entreprises</td>\n      <td>Sika: le fabricant prévoit une embellie au deuxième semestre</td>\n      <td>NaN</td>\n      <td>Le fabricant de spécialités chimiques Sika s'attend à une embellie au deuxième semestre malgré la crise pandémique qui continue de créer l'incertitude sur les marchés. Paul Schuler, directeur géné...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AGE</td>\n      <td>Agefi</td>\n      <td>2020-10-01</td>\n      <td>fr</td>\n      <td>marchés</td>\n      <td>SMI dans le rouge, sous les 10.200 points</td>\n      <td>NaN</td>\n      <td>Le SMI a perdu 0,41% à 10.187,090 points, plus bas à 10.169,78 et plus haut à 10.266,97. Le SLI a cédé 0,08% à 1553,69 points et le SPI 0,27% à 12.724,65 points.Après avoir fait une pointe durant ...</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Concatenate all files in the list \"filenames_older\" to one dataframe\n",
    "agg_older = pd.concat([pd.read_csv(f, usecols = ['source', 'source_full', 'date', 'lang', 'news_section', 'title', 'subtitle', 'article', 'author'],\n",
    "                                   dtype = {'source': object, 'source_full': object, 'date': object, 'lang': object, 'news_section': object,\n",
    "                                            'title': object, 'subtitle': object, 'article': object, 'author': object}) for f in filenames_older])\n",
    "\n",
    "# Rearrange to order of the columns\n",
    "agg_older = agg_older[['source', 'source_full', 'date', 'lang', 'news_section', 'title', 'subtitle', 'article', 'author']]\n",
    "\n",
    "# Rename the columns where needed\n",
    "agg_older.rename(columns = {\"source\": \"so\", \"source_full\": \"so_txt\", \"date\": \"pubDateTime\", \"lang\": \"la\", \"article\": \"tx\"}, inplace = True)\n",
    "\n",
    "# Lowercase the entries of the columns 'la' and 'news_section' (to ensure data conformity)\n",
    "agg_older['la'] = agg_older['la'].str.lower()\n",
    "agg_older['news_section'] = agg_older['news_section'].str.lower()\n",
    "\n",
    "# Take a look at the created dataframe\n",
    "agg_older.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2141522, 9)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Take a look at the shape of the created dataframe\n",
    "agg_older.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the concatenated dataframe 'agg_older' as a csv\n",
    "agg_older.to_csv(\"agg_older.csv\", index = False, encoding = 'utf-8-sig')\n",
    "\n",
    "# Remove the dataframe to save RAM\n",
    "del agg_older"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    so so_txt pubDateTime  la news_section  \\\n",
       "0  AGE  Agefi  2020-10-01  fr  entreprises   \n",
       "1  AGE  Agefi  2020-10-01  fr  entreprises   \n",
       "2  AGE  Agefi  2020-10-01  fr  entreprises   \n",
       "\n",
       "                                                                                     title  \\\n",
       "0  Lonza: le groupe aurait débuté le processus de vente des activités ingrédients spéciaux   \n",
       "1                                       L'aviation d'affaires reporte ses espoirs sur 2021   \n",
       "2                                             Firmenich: nouvelle usine inaugurée à Genève   \n",
       "\n",
       "                                                                                                                                                                                     subtitle  \\\n",
       "0                                                                                                                                                                                         NaN   \n",
       "1  Jets privés. Malgré un carnet de réservations bien remplis cet été, la fin d'année s'annonce compliquée en raison de la perte de la clientèle d'entreprise et des restrictions politiques.   \n",
       "2                                                                                                                                                                                         NaN   \n",
       "\n",
       "                                                                                                                                                                                                        tx  \\\n",
       "0  Lonza aurait entamé le processus de vente de ses affaires dans les composants chimiques spéciaux, Lonza Specialty Ingredients (LSI), croit savoir l'agence Reuters sur la base de sources proches du...   \n",
       "1  stéphanie giroud«Nous avons eu un très bon été en termes de nombre de vols, mais en termes de valeur, c'est catastrophique.» Eymeric Segard, CEO de LunaJets, ne veut pas céder à un optimisme passa...   \n",
       "2  Firmenich a ouvert sa nouvelle usine pilote et laboratoire en biotechnologie et produits naturels à Genève, a-t-il annoncé mercredi. Geneviève Berger, directrice des recherches chez Firmenich, a p...   \n",
       "\n",
       "  author  \n",
       "0    NaN  \n",
       "1    NaN  \n",
       "2    NaN  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>so</th>\n      <th>so_txt</th>\n      <th>pubDateTime</th>\n      <th>la</th>\n      <th>news_section</th>\n      <th>title</th>\n      <th>subtitle</th>\n      <th>tx</th>\n      <th>author</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AGE</td>\n      <td>Agefi</td>\n      <td>2020-10-01</td>\n      <td>fr</td>\n      <td>entreprises</td>\n      <td>Lonza: le groupe aurait débuté le processus de vente des activités ingrédients spéciaux</td>\n      <td>NaN</td>\n      <td>Lonza aurait entamé le processus de vente de ses affaires dans les composants chimiques spéciaux, Lonza Specialty Ingredients (LSI), croit savoir l'agence Reuters sur la base de sources proches du...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AGE</td>\n      <td>Agefi</td>\n      <td>2020-10-01</td>\n      <td>fr</td>\n      <td>entreprises</td>\n      <td>L'aviation d'affaires reporte ses espoirs sur 2021</td>\n      <td>Jets privés. Malgré un carnet de réservations bien remplis cet été, la fin d'année s'annonce compliquée en raison de la perte de la clientèle d'entreprise et des restrictions politiques.</td>\n      <td>stéphanie giroud«Nous avons eu un très bon été en termes de nombre de vols, mais en termes de valeur, c'est catastrophique.» Eymeric Segard, CEO de LunaJets, ne veut pas céder à un optimisme passa...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AGE</td>\n      <td>Agefi</td>\n      <td>2020-10-01</td>\n      <td>fr</td>\n      <td>entreprises</td>\n      <td>Firmenich: nouvelle usine inaugurée à Genève</td>\n      <td>NaN</td>\n      <td>Firmenich a ouvert sa nouvelle usine pilote et laboratoire en biotechnologie et produits naturels à Genève, a-t-il annoncé mercredi. Geneviève Berger, directrice des recherches chez Firmenich, a p...</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Concatenate all files in the list \"filenames_oct_to_jan\" to one dataframe\n",
    "agg_oct_to_jan = pd.concat([pd.read_csv(f, usecols = ['so', 'so_txt', 'pubDateTime', 'la', 'ru', 'ht', 'ut', 'tx', 'annotation_person'],\n",
    "                                        dtype = {'so': object, 'so_txt': object, 'pubDateTime': object, 'la': object, 'ru': object,\n",
    "                                                 'ht': object, 'ut': object, 'tx': object, 'annotation_person': object}) for f in filenames_oct_to_jan])\n",
    "\n",
    "# Rename the columns where needed\n",
    "agg_oct_to_jan.rename(columns = {\"ru\": \"news_section\", \"ht\": \"title\", \"ut\": \"subtitle\", \"annotation_person\": \"author\"}, inplace = True)\n",
    "\n",
    "# Lowercase the entries of the columns 'la' and 'news_section' (to ensure data conformity)\n",
    "agg_oct_to_jan['la'] = agg_oct_to_jan['la'].str.lower()\n",
    "agg_oct_to_jan['news_section'] = agg_oct_to_jan['news_section'].str.lower()\n",
    "\n",
    "# Take a look at the created dataframe\n",
    "agg_oct_to_jan.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(387521, 9)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Take a look at the shape of the created dataframe\n",
    "agg_oct_to_jan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the concatenated dataframe 'agg_oct_to_jan' as a csv\n",
    "agg_oct_to_jan.to_csv(\"agg_oct_to_jan.csv\", index = False, encoding = 'utf-8-sig')\n",
    "\n",
    "# Remove the dataframe to save RAM\n",
    "del agg_oct_to_jan"
   ]
  },
  {
   "source": [
    "<div class=\"alert alert-info\" style=\"background-color:#5d3a8e; color:white; padding:0px 10px; border-radius:5px;\"><h3 style='margin:10px 5px'> \n",
    "1.2 Overall Aggregation\n",
    "</h3>\n",
    "</div>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    so so_txt pubDateTime  la  news_section  \\\n",
       "0  AGE  Agefi  2020-10-01  fr        la der   \n",
       "1  AGE  Agefi  2020-10-01  fr   entreprises   \n",
       "2  AGE  Agefi  2020-10-01  fr       marchés   \n",
       "\n",
       "                                                          title subtitle  \\\n",
       "0                     Les trois indices\\nclôturent dans le vert      NaN   \n",
       "1  Sika: le fabricant prévoit une embellie au deuxième semestre      NaN   \n",
       "2                     SMI dans le rouge, sous les 10.200 points      NaN   \n",
       "\n",
       "                                                                                                                                                                                                        tx  \\\n",
       "0  La Bourse de New York a terminé en hausse mercredi, sur les espoirs d'un prochain accord sur un nouveau plan d'aide économique américain qui a mené le Dow Jones brièvement au-dessus de 2% en séanc...   \n",
       "1  Le fabricant de spécialités chimiques Sika s'attend à une embellie au deuxième semestre malgré la crise pandémique qui continue de créer l'incertitude sur les marchés. Paul Schuler, directeur géné...   \n",
       "2  Le SMI a perdu 0,41% à 10.187,090 points, plus bas à 10.169,78 et plus haut à 10.266,97. Le SLI a cédé 0,08% à 1553,69 points et le SPI 0,27% à 12.724,65 points.Après avoir fait une pointe durant ...   \n",
       "\n",
       "                               author  \n",
       "0  McConnell, Mitch...Mnuchin, Steven  \n",
       "1                                 NaN  \n",
       "2                                 NaN  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>so</th>\n      <th>so_txt</th>\n      <th>pubDateTime</th>\n      <th>la</th>\n      <th>news_section</th>\n      <th>title</th>\n      <th>subtitle</th>\n      <th>tx</th>\n      <th>author</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AGE</td>\n      <td>Agefi</td>\n      <td>2020-10-01</td>\n      <td>fr</td>\n      <td>la der</td>\n      <td>Les trois indices\\nclôturent dans le vert</td>\n      <td>NaN</td>\n      <td>La Bourse de New York a terminé en hausse mercredi, sur les espoirs d'un prochain accord sur un nouveau plan d'aide économique américain qui a mené le Dow Jones brièvement au-dessus de 2% en séanc...</td>\n      <td>McConnell, Mitch...Mnuchin, Steven</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AGE</td>\n      <td>Agefi</td>\n      <td>2020-10-01</td>\n      <td>fr</td>\n      <td>entreprises</td>\n      <td>Sika: le fabricant prévoit une embellie au deuxième semestre</td>\n      <td>NaN</td>\n      <td>Le fabricant de spécialités chimiques Sika s'attend à une embellie au deuxième semestre malgré la crise pandémique qui continue de créer l'incertitude sur les marchés. Paul Schuler, directeur géné...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AGE</td>\n      <td>Agefi</td>\n      <td>2020-10-01</td>\n      <td>fr</td>\n      <td>marchés</td>\n      <td>SMI dans le rouge, sous les 10.200 points</td>\n      <td>NaN</td>\n      <td>Le SMI a perdu 0,41% à 10.187,090 points, plus bas à 10.169,78 et plus haut à 10.266,97. Le SLI a cédé 0,08% à 1553,69 points et le SPI 0,27% à 12.724,65 points.Après avoir fait une pointe durant ...</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Define a list containing the names of the pre-aggregated files we want to merge together\n",
    "all_filenames = [\"agg_older.csv\", \"agg_oct_to_jan.csv\"]\n",
    "\n",
    "# Concatenate all files in the list to one dataframe\n",
    "agg_csv = pd.concat([pd.read_csv(f, dtype = {'so': object, 'so_txt': object, 'pubDateTime': object, 'la': object, 'news_section': object,\n",
    "                                             'title': object, 'subtitle': object, 'tx': object, 'author': object}) for f in all_filenames])\n",
    "# Give an article specific unique index\n",
    "agg_csv.index = np.arange(agg_csv.shape[0])\n",
    "\n",
    "# Take a look at the aggregated dataframe\n",
    "agg_csv.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2529043, 9)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Take a look at the shape of the aggregated dataframe\n",
    "agg_csv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "so                    0\n",
       "so_txt            73743\n",
       "pubDateTime           0\n",
       "la                    0\n",
       "news_section      49563\n",
       "title                 3\n",
       "subtitle        2315694\n",
       "tx                38660\n",
       "author          1407394\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Check how many missing values are contained in each column\n",
    "agg_csv.isna().sum()"
   ]
  },
  {
   "source": [
    "We observe that the data contains several observations with missing article text. As these observations are useless, we drop them from the data in the following"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove observations with missing article text\n",
    "agg_csv.drop(agg_csv.loc[agg_csv.tx.isnull()].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array(['de', 'en', 'fr', 'it', 'rm'], dtype=object),\n",
       " array([1973647,    2118,  490609,   23919,      90], dtype=int64))"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# Inspect the different languages in which the articles are written including article counts per language\n",
    "np.unique(agg_csv.la, return_counts = True)"
   ]
  },
  {
   "source": [
    "We observe that the articles are written in 5 different languages:\n",
    "\n",
    "- German (de)\n",
    "- English (en)\n",
    "- French (fr)\n",
    "- Italian (it)\n",
    "- Roman (rm)\n",
    "\n",
    "As the commonly used text processing packages are not available for the Roman language, I decide to remove the according articles from the dataset (which anyway only constitute a small fraction of the data)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove articles that are written in roman\n",
    "agg_csv.drop(agg_csv[agg_csv.la == 'rm'].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "49110 duplicates have been removed.\n"
     ]
    }
   ],
   "source": [
    "# Identify the number of duplicates (according to news source, publication date and article text)\n",
    "n_duplicates = sum(agg_csv.duplicated(subset = ['so','pubDateTime','tx'], keep = 'first'))\n",
    "\n",
    "# Remove identified duplicates and create a new index (from 0 to n-1)\n",
    "agg_csv.drop_duplicates(subset = ['so','pubDateTime','tx'], keep = 'first', inplace = True, ignore_index = True)\n",
    "\n",
    "# Display the number of removed duplicates\n",
    "print(n_duplicates, \"duplicates have been removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array(['de', 'en', 'fr', 'it'], dtype=object),\n",
       " array([1934313,    2087,  481162,   23621], dtype=int64))"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# Check how many articles are left per language after removing identified duplicates\n",
    "np.unique(agg_csv.la, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "so                      object\n",
       "so_txt                  object\n",
       "pubDateTime     datetime64[ns]\n",
       "la                      object\n",
       "news_section            object\n",
       "title                   object\n",
       "subtitle                object\n",
       "tx                      object\n",
       "author                  object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# Transform pubDateTime into a date\n",
    "agg_csv.pubDateTime = pd.to_datetime(agg_csv.pubDateTime, yearfirst = True)\n",
    "\n",
    "# Take a look at the types of the columns\n",
    "agg_csv.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "so                    0\n",
       "so_txt            71291\n",
       "pubDateTime           0\n",
       "la                    0\n",
       "news_section      45603\n",
       "title                 3\n",
       "subtitle        2268369\n",
       "tx                    0\n",
       "author          1365184\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# Check how many missing values are contained in each column\n",
    "agg_csv.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2441183, 9)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# Take a look at the shape of the data\n",
    "agg_csv.shape"
   ]
  },
  {
   "source": [
    "<div class=\"alert alert-info\" style=\"background-color:#5d3a8e; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'> \n",
    "2. Extract the article text from the subtitle where these have been confused by mistake\n",
    "</h2>\n",
    "</div>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the index of the according articles\n",
    "idx_confused_1 = np.arange(59019, 65923+1).tolist()\n",
    "idx_confused_2 = np.arange(684119, 702950+1).tolist()\n",
    "idx_confused_2.append(2064755)\n",
    "idx_confused = np.concatenate((np.array(idx_confused_1), np.array(idx_confused_2))).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "25738"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "len(idx_confused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Hallk\\.conda\\envs\\Master_Thesis_env\\lib\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "# Change the entrie of the tx column where needed\n",
    "agg_csv['tx'].loc[idx_confused] = agg_csv['subtitle'].loc[idx_confused]"
   ]
  },
  {
   "source": [
    "<div class=\"alert alert-info\" style=\"background-color:#5d3a8e; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'> \n",
    "3. Export the aggregated csv-file \n",
    "</h2>\n",
    "</div>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the concatenated dataframe as a full csv\n",
    "agg_csv.to_csv(\"agg_csv.csv\", encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the concatenated dataframe as a sparse csv\n",
    "agg_csv.to_csv(\"agg_csv_sparse.csv\", columns = ['so', 'la', 'tx'], encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the subsample of all articles that are written in a specific language separately\n",
    "agg_csv[agg_csv.la == 'de'].to_csv(\"agg_csv_sparse_de.csv\", columns = ['so', 'la', 'tx'], encoding = 'utf-8-sig')\n",
    "agg_csv[agg_csv.la == 'en'].to_csv(\"agg_csv_sparse_en.csv\", columns = ['so', 'la', 'tx'], encoding = 'utf-8-sig')\n",
    "agg_csv[agg_csv.la == 'fr'].to_csv(\"agg_csv_sparse_fr.csv\", columns = ['so', 'la', 'tx'], encoding = 'utf-8-sig')\n",
    "agg_csv[agg_csv.la == 'it'].to_csv(\"agg_csv_sparse_it.csv\", columns = ['so', 'la', 'tx'], encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data back in as follows\n",
    "#de_tx = pd.read_csv(\"agg_csv_sparse_de.csv\", index_col = 0)\n",
    "#en_tx = pd.read_csv(\"agg_csv_sparse_en.csv\", index_col = 0)\n",
    "#fr_tx = pd.read_csv(\"agg_csv_sparse_fr.csv\", index_col = 0)\n",
    "#it_tx = pd.read_csv(\"agg_csv_sparse_it.csv\", index_col = 0)"
   ]
  }
 ]
}